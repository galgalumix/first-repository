import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import time
from datetime import datetime
import random
from fake_useragent import UserAgent

#hello my team 


ua = UserAgent()

headers = {
    'User-Agent': ua.random,
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
}

session =  requests.Session()
session.headers.update(headers)

print("í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

url = "https://news.google.com/home?hl=ko&gl=KR&ceid=KR%3Ako"
reponse = session.get(url, headers= headers )
print(reponse.text)

def craw_nems_headline():
    base_url = "https://news.google.com/home?hl=ko&gl=KR&ceid=KR%3Ako"
    
    news_data = []
    
    
    
    
    try:
        reponse = session.get(base_url)
        reponse.raise_for_status()
        
        soup = BeautifulSoup(reponse.content, 'html.parser')
        
        headline = soup.find_all('h2', class_= 'headline' )
        
        
        for i ,headline in enumerate(headline, 1 ):
            news_item = {
                'title' : headline,
                'url' : f"hhttps://news.google.com/home?hl=ko&gl=KR&ceid=KR%3Ako,{i}",
                'crawl_tiem' : datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            news_data.append(news_item)
        print(f"âœ… {len(news_data)}ê°œì˜ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘ ì™„ë£Œ!")
    except Exception as e:
         print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
         
         
    return news_data

def save_newsdata(news_data):
    
    
    if news_data:
        df = pd.DataFrame(news_data)
        filename = f"news_headlines_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(filename, index= False, encoding= 'utf-8-sig')
        print(f"âœ… ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return df
    else :
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None


news_data = craw_nems_headline()
df = save_newsdata(news_data)
if df is not None:
    print("\nğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
    print(df.head())
        
